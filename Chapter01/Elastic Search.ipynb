{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab31278c-c1f7-4e09-827f-2ca3e9b49a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88639ad2-bac5-4a70-9322-8a72e4c934b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"dd002994c245\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"_YfCdMT3RO-1ukVJNJ122w\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.4.3\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
      "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.3.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0f22a6c-bd7c-49cd-8f03-c10f3eca9f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "202a3e45-12e9-487e-92a0-d9229444203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ece13ae2-9014-4146-9703-e92ebd6cd4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'b9363d650db0', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'AlU1npKAS9KL9Zvr0F1RWA', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "print(client.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a670625b-8f7e-4ced-b8d8-33e8dd0dcfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a595af4-91f0-4827-a6fb-0bbe38a4674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'course-questions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "12b27081-6721-499f-b50b-c05668c52f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e80b0d59-1a76-482e-a9f6-ddbc2d9ef4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'r') as fp:\n",
    "    docs_raw = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10c37ab1-231b-4cb5-9245-001d1d7191bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "for docs in docs_raw:\n",
    "   for doc in docs['documents']:\n",
    "       doc['course'] = docs['course']\n",
    "       document.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef920b81-71cc-40be-abac-6f92f819ae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bba9e40f-16a4-453c-8363-21226917dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:18<00:00, 50.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(document):\n",
    "    client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68dd9dba-1d36-443b-a416-e9ef103a6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'can i still join?'\n",
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45ebbcfd-f6e3-491a-a565-c5c6a4352095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = client.search(index = index_name, body=search_query)\n",
    "    result_doc = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_doc.append(hit['_source'])\n",
    "\n",
    "    return result_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd865ab4-fb09-4d0d-b77e-198bc23eb2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_result):\n",
    "    prompt_template = '''\n",
    "    You're a course teaching assistant. Answer the QUESTION base on the CONTEXT from the FAQ database.\n",
    "    use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    if the CONTEXT doesn't contain the answer, output NONE.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \n",
    "    '''.strip()\n",
    "    context = ''\n",
    "\n",
    "    for doc in search_result: \n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7eeb6631-ca63-431e-b4d3-bcba880f64aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    model = \"mistral-small-latest\"\n",
    "    \n",
    "    client = MistralClient(api_key=api_key)\n",
    "    \n",
    "    chat_response = client.chat(\n",
    "    model=model,\n",
    "    messages=[ChatMessage(role=\"user\", content=prompt)]\n",
    "    )\n",
    "\n",
    "\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d22c83cc-0664-4efc-aa60-0b30795ac901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_result = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_result)\n",
    "    return llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf479dbe-b306-41f4-bca9-05d9af3a5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get the certificate for the course, you need to finish the course with a “live” cohort. This is because you need to peer-review capstone(s) after submitting a project, which can only be done at the time the course is running. Unfortunately, certificates are not awarded for the self-paced mode.\n"
     ]
    }
   ],
   "source": [
    "print(rag('how do I get the certificate for the course?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904fb0f-fd45-4945-8ef1-f3a3cdb467ba",
   "metadata": {},
   "source": [
    "## query to answer the homework question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1451e63c-8aaa-4c69-a3dc-c451b61cfdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.050095"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use only question and text fields and give question a boost of 4, and use \"type\": \"best_fields\".\n",
    "\n",
    "query = 'How do I execute a command in a running docker container?'\n",
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "client.search(index=index_name, body=search_query)['hits']['max_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1e5af022-9f98-4013-bd39-f344bc39c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's only limit the questions to machine-learning-zoomcamp.\n",
    "\n",
    "#Return 3 results. What's the 3rd question returned by the search engine?\n",
    "search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "response = client.search(index=index_name, body=search_query)['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c37abc9c-cca4-446f-a306-f13813eca461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'course-questions', '_id': 'zkf0RpABbwD9Yvr-74j-', '_score': 49.938507, '_source': {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from a different folder into docker container’s working directory?', 'course': 'machine-learning-zoomcamp'}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0ee04f69-2c6e-45ec-9c45-c61103befabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bc05b65c-bdf9-49b8-b4bf-ebb926cc4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd3a6792-1fb5-411c-a422-5a85c9d5839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ''\n",
    "for doc in response:\n",
    "    context = context + context_template.format(question=doc['_source']['question'], text=doc['_source']['text']) + '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85e02ef1-3398-41df-82c9-a08dd1ede53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=query, context=context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "183ed1ab-8e1d-423c-9e35-8ee375da3fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cd4366d6-272e-4fa4-81ce-2faadadcb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.5.15 tiktoken-0.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7160bf7d-548f-4342-aa75-1c9b95844937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1788e72a-b358-4ab3-ad32-54da1b5b07b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f3f11f4f-10f0-482a-8641-38f3ac3d60c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
